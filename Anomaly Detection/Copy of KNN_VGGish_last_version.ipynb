{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10aE5s5tmvjuLSYVKsArydDYeVFPE_eqA","timestamp":1718621569331}],"authorship_tag":"ABX9TyOYLVfXIa9NmzZ608kULkZc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns  # Import seaborn for enhanced visualizations\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import average_precision_score, confusion_matrix, roc_curve, precision_recall_curve"],"metadata":{"id":"KWmwFFMwHvlH","executionInfo":{"status":"ok","timestamp":1718618378735,"user_tz":-180,"elapsed":387,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2tpq-dYHKbg","executionInfo":{"status":"ok","timestamp":1718618397826,"user_tz":-180,"elapsed":17641,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"5a35ff0e-6a03-41cc-87dd-fe4b32eb9679"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["def concatenate_numpy_arrays_from_folder(directory):\n","    \"\"\"\n","    Concatenates all numpy arrays in the specified directory into a single numpy array.\n","\n","    Args:\n","        directory (str): The path to the directory containing the numpy array files.\n","\n","    Returns:\n","        np.ndarray: The concatenated numpy array.\n","    \"\"\"\n","    # Initialize an empty list to store the arrays\n","    arrays_list = []\n","\n","    # Loop through all files in the directory\n","    for filename in os.listdir(directory):\n","        if filename.endswith('.npy'):  # Check if the file is a numpy array file\n","            file_path = os.path.join(directory, filename)\n","\n","            # Load the numpy array from the file\n","            numpy_array = np.load(file_path)\n","\n","            # Print the shape of the numpy array\n","            #print(f'Shape of {filename}: {numpy_array.shape}')\n","\n","            # Append the numpy array to the list\n","            arrays_list.append(numpy_array)\n","\n","    # Concatenate all numpy arrays in the list into a single array\n","    concatenated_array = np.concatenate(arrays_list, axis=0)  # Change axis if needed\n","\n","    # Print the shape of the concatenated array\n","    print(f'Shape of the concatenated array: {concatenated_array.shape}')\n","\n","    return concatenated_array"],"metadata":{"id":"QwRR0hJ_HUX6","executionInfo":{"status":"ok","timestamp":1718618400642,"user_tz":-180,"elapsed":321,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# for 5 secondes samples\n","\n","# test_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_ad/test_embeddings_ads'\n","# ad_test_embeddings = concatenate_numpy_arrays_from_folder(test_ads_directory)\n","\n","# val_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_ad/val_embeddings_ads'\n","# ad_val_embeddings = concatenate_numpy_arrays_from_folder(val_ads_directory)\n","\n","# train_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_ad/train_embeddings_ads'\n","# ad_train_embeddings = concatenate_numpy_arrays_from_folder(train_ads_directory)\n","\n","\n","# test_pods_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_podcast/test_embeddings'\n","# pod_test_embeddings = concatenate_numpy_arrays_from_folder(test_pods_directory)\n","\n","# val_pods_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_podcast/val_embeddings'\n","# pod_val_embeddings = concatenate_numpy_arrays_from_folder(val_pods_directory)\n","\n","# train_pod_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_5sec/grouped_embeddings_podcast/train_embeddings'\n","# pod_train_embeddings = concatenate_numpy_arrays_from_folder(train_pod_directory)[:507, :, :]\n","\n","# print(pod_train_embeddings.shape)\n"],"metadata":{"id":"8l80_PFAHW-6","executionInfo":{"status":"ok","timestamp":1718609986925,"user_tz":-180,"elapsed":292,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# for 1 secondes samples\n","\n","test_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_ad/test_embeddings_ads'\n","ad_test_embeddings = concatenate_numpy_arrays_from_folder(test_ads_directory)\n","\n","val_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_ad/val_embeddings_ads'\n","ad_val_embeddings = concatenate_numpy_arrays_from_folder(val_ads_directory)\n","\n","train_ads_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_ad/train_embeddings_ads'\n","ad_train_embeddings = concatenate_numpy_arrays_from_folder(train_ads_directory)\n","\n","\n","test_pods_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_podcast/test_embeddings_pods'\n","pod_test_embeddings = concatenate_numpy_arrays_from_folder(test_pods_directory)\n","\n","val_pods_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_podcast/val_embeddings_pods'\n","pod_val_embeddings = concatenate_numpy_arrays_from_folder(val_pods_directory)\n","\n","train_pod_directory = '/content/drive/MyDrive/AD-Blocker Project/grouped_embeddings/vggish_1sec/grouped_embeddings_podcast/train_embeddings_pods'\n","pod_train_embeddings = concatenate_numpy_arrays_from_folder(train_pod_directory)[:2597, :, :]\n","\n","print(pod_train_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LOQgcgHYHY6-","executionInfo":{"status":"ok","timestamp":1718618428987,"user_tz":-180,"elapsed":25294,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"3a4f696e-6471-4844-9be8-191995c474b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the concatenated array: (302, 1, 128)\n","Shape of the concatenated array: (319, 1, 128)\n","Shape of the concatenated array: (2597, 1, 128)\n","Shape of the concatenated array: (668, 1, 128)\n","Shape of the concatenated array: (1940, 1, 128)\n","Shape of the concatenated array: (6115, 1, 128)\n","(2597, 1, 128)\n"]}]},{"cell_type":"code","source":["def convert_to_2d_array(three_d_array):\n","    # Get the dimensions of the input array\n","    depth, rows, cols = three_d_array.shape\n","\n","    # Reshape each 2D array to 1D and concatenate them\n","    flattened_arrays = [matrix.flatten() for matrix in three_d_array]\n","    two_d_array = np.vstack(flattened_arrays)\n","\n","    return two_d_array"],"metadata":{"id":"H13uAoA7HbNt","executionInfo":{"status":"ok","timestamp":1718618433852,"user_tz":-180,"elapsed":382,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pod_train_embeddings = convert_to_2d_array(pod_train_embeddings)\n","ad_train_embeddings = convert_to_2d_array(ad_train_embeddings)\n","\n","pod_val_embeddings = convert_to_2d_array(pod_val_embeddings)\n","ad_val_embeddings = convert_to_2d_array(ad_val_embeddings)\n","\n","pod_test_embeddings =  convert_to_2d_array(pod_test_embeddings)\n","ad_test_embeddings = convert_to_2d_array(ad_test_embeddings)\n","\n","print(pod_train_embeddings.shape)\n","print(ad_train_embeddings.shape)\n","\n","print(pod_val_embeddings.shape)\n","print(ad_val_embeddings.shape)\n","\n","print(pod_test_embeddings.shape)\n","print(ad_test_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAD1CQnwHdid","executionInfo":{"status":"ok","timestamp":1718618435135,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"c54ce6e3-56c2-40db-cb4a-375a6df0d265"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(2597, 128)\n","(2597, 128)\n","(1940, 128)\n","(319, 128)\n","(668, 128)\n","(302, 128)\n"]}]},{"cell_type":"code","source":["train_embeddings = np.concatenate((pod_train_embeddings, ad_train_embeddings))\n","val_embeddings = np.concatenate((pod_val_embeddings, ad_val_embeddings))\n","test_embeddings = np.concatenate((pod_test_embeddings, ad_test_embeddings))"],"metadata":{"id":"Ou3DVC5XHgOZ","executionInfo":{"status":"ok","timestamp":1718618437055,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def concatenate_zeros_and_ones(podcast_length, commercials_length):\n","    # Create array of zeros with size of podcast array\n","    zeros_array = np.zeros(podcast_length, dtype=int)\n","\n","    # Create array of ones with size of commercials array\n","    ones_array = np.ones(commercials_length, dtype=int)\n","\n","    # Concatenate arrays\n","    concatenated_array = np.concatenate((zeros_array, ones_array))\n","\n","    return concatenated_array"],"metadata":{"id":"tHGjEnXIHjxp","executionInfo":{"status":"ok","timestamp":1718618439352,"user_tz":-180,"elapsed":520,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_labels = concatenate_zeros_and_ones(pod_train_embeddings.shape[0], ad_train_embeddings.shape[0])\n","val_labels = concatenate_zeros_and_ones(pod_val_embeddings.shape[0], ad_val_embeddings.shape[0])\n","test_lables = concatenate_zeros_and_ones(pod_test_embeddings.shape[0], ad_test_embeddings.shape[0])"],"metadata":{"id":"5u-RtaAgHlNN","executionInfo":{"status":"ok","timestamp":1718618440987,"user_tz":-180,"elapsed":365,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_knn_model(normal_embeddings, n_neighbors=11):\n","    \"\"\"\n","    Trains a K-Nearest Neighbors (KNN) classifier on the provided normal embeddings.\n","\n","    Parameters:\n","    ---------\n","    - normal_embeddings (numpy.ndarray): Embeddings of normal class samples for training.\n","    - n_neighbors (int, optional): Number of neighbors to consider. Default is 11.\n","\n","    Returns:\n","    -------\n","    - sklearn.neighbors.KNeighborsClassifier: Trained KNN classifier.\n","    \"\"\"\n","    # Create a KNN classifier with the specified number of neighbors\n","    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n","\n","    # Label all normal embeddings as 0\n","    labels = np.zeros(len(normal_embeddings)) # check this line with odelia, why do we need to provied array of zeros if we already know what are the labels\n","\n","    # Train the KNN classifier\n","    knn_classifier.fit(normal_embeddings, labels)\n","\n","    return knn_classifier"],"metadata":{"id":"qTSA7O5RIFW9","executionInfo":{"status":"ok","timestamp":1718618443102,"user_tz":-180,"elapsed":446,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","trained_knn_classifier = train_knn_model(pod_train_embeddings, n_neighbors=60)"],"metadata":{"id":"fimMCPcjIJIs","executionInfo":{"status":"ok","timestamp":1718618447120,"user_tz":-180,"elapsed":278,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def calculate_mean_distances(knn_model, embeddings):\n","    \"\"\"\n","    Calculates the mean distances of embeddings using the trained KNN model.\n","\n","    Parameters:\n","    ----------\n","    - knn_model (sklearn.neighbors.KNeighborsClassifier): Trained KNN model.\n","    - embeddings (numpy.ndarray): Embeddings to calculate distances for.\n","\n","    Returns:\n","    -------\n","    - numpy.ndarray: Mean distances of embeddings.\n","    \"\"\"\n","    # Find distances and indices of k-neighbors for each embedding\n","    distances, _ = knn_model.kneighbors(embeddings)\n","\n","    # Calculate mean distances for each embedding\n","    mean_distances = distances.mean(axis=1)\n","\n","    return mean_distances"],"metadata":{"id":"6F6N0SSTILjE","executionInfo":{"status":"ok","timestamp":1718618448778,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def calculate_thresholds(knn_model, anomaly_embeddings_train, normal_embeddings_train):\n","    \"\"\"\n","    Calculates anomaly and normal thresholds based on mean distances of embeddings using a trained KNN model.\n","\n","    Parameters:\n","    ----------\n","    - knn_model (sklearn.neighbors.KNeighborsClassifier): Trained KNN model.\n","    - anomaly_embeddings_train (numpy.ndarray): Embeddings of anomaly class samples for training.\n","    - normal_embeddings_train (numpy.ndarray): Embeddings of normal class samples for training.\n","\n","    Returns:\n","    -------\n","    - Anomaly threshold (float)\n","    - Normal threshold (float)\n","    \"\"\"\n","    # Calculate mean distances for anomaly and normal embeddings\n","    anomaly_mean_distance = calculate_mean_distances(knn_model, anomaly_embeddings_train)\n","    normal_mean_distance = calculate_mean_distances(knn_model, normal_embeddings_train)\n","\n","    # Determine threshold based on means and factors\n","    anomaly_threshold = anomaly_mean_distance.mean() + 2 * anomaly_mean_distance.std()  # Set threshold 2 standard deviations above anomaly mean\n","    normal_threshold = normal_mean_distance.mean() - 2 * normal_mean_distance.std()  # Set threshold 2 standard deviations below normal mean\n","\n","    return anomaly_threshold, normal_threshold"],"metadata":{"id":"Pm7bKmTdIMIF","executionInfo":{"status":"ok","timestamp":1718618451263,"user_tz":-180,"elapsed":330,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Call the function to calculate thresholds\n","anomaly_threshold, normal_threshold = calculate_thresholds(trained_knn_classifier, ad_train_embeddings, pod_train_embeddings)\n","\n","# Print the calculated thresholds\n","print(\"Anomaly threshold:\", anomaly_threshold)\n","print(\"Normal threshold:\", normal_threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ReNOxtS1IPUY","executionInfo":{"status":"ok","timestamp":1718618453804,"user_tz":-180,"elapsed":740,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"9294adfe-ad03-4534-efcc-c834e77dbc39"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Anomaly threshold: 6.1433550443179925\n","Normal threshold: 1.3256375932644553\n"]}]},{"cell_type":"code","source":["def validate_knn_model(knn_model, validation_embeddings, anomaly_threshold, normal_threshold, true_validation_labels):\n","    \"\"\"\n","    Validates the KNN model using validation embeddings.\n","\n","    Parameters:\n","    ----------\n","    - knn_model (sklearn.neighbors.KNeighborsClassifier): Trained KNN model.\n","    - validation_embeddings (numpy.ndarray): Validation embeddings.\n","    - anomaly_threshold (float): Threshold for classifying anomalies.\n","    - normal_threshold (float): Threshold for classifying normal samples.\n","    - true_validation_labels (numpy.ndarray): True labels of validation samples.\n","\n","    Returns:\n","    -------\n","    - Validation accuracy (float)\n","    - Validation predictions (numpy.ndarray)\n","    - Threshold used for classification (float)\n","    \"\"\"\n","    # Calculate distances to nearest neighbors\n","    distances, _ = knn_model.kneighbors(validation_embeddings)\n","\n","    # Calculate mean distances for each validation embedding\n","    mean_distances = distances.mean(axis=1)\n","\n","    # Calculate threshold for classification\n","    threshold = (anomaly_threshold + normal_threshold) / 2\n","\n","    # Classify validation embeddings based on mean distances\n","    validation_predictions = mean_distances > threshold\n","\n","    # Calculate validation accuracy\n","    validation_accuracy = accuracy_score(true_validation_labels, validation_predictions)\n","\n","    return validation_accuracy, validation_predictions, threshold"],"metadata":{"id":"mixPWlFEIRZM","executionInfo":{"status":"ok","timestamp":1718618456647,"user_tz":-180,"elapsed":288,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Call the function and store the return values\n","validation_accuracy, validation_predictions, threshold = validate_knn_model(trained_knn_classifier, val_embeddings, anomaly_threshold, normal_threshold, val_labels)\n","\n","# Print the different results\n","print(\"Validation Accuracy:\", validation_accuracy)\n","print(\"Validation Predictions:\", validation_predictions)\n","print(\"Threshold:\", threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4dn6_nmIU6B","executionInfo":{"status":"ok","timestamp":1718618459554,"user_tz":-180,"elapsed":443,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"8a43373f-d760-4519-aba4-e36ea505d890"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.8154050464807437\n","Validation Predictions: [False False False ... False False False]\n","Threshold: 3.7344963187912237\n"]}]},{"cell_type":"code","source":["def test_knn_model(knn_model, test_embeddings, anomaly_threshold, normal_threshold, true_test_labels):\n","    \"\"\"\n","    Tests the KNN model using test embeddings.\n","\n","    Parameters:\n","    ---------\n","    - knn_model (sklearn.neighbors.KNeighborsClassifier): Trained KNN model.\n","    - test_embeddings (numpy.ndarray): Test embeddings.\n","    - anomaly_threshold (float): Threshold for classifying anomalies.\n","    - normal_threshold (float): Threshold for classifying normal samples.\n","    - true_test_labels (numpy.ndarray): True labels of test samples.\n","\n","    Returns:\n","    -------\n","    - Test accuracy (float)\n","    - Test predictions (numpy.ndarray)\n","    - Threshold used for classification (float)\n","    \"\"\"\n","    # Calculate distances to nearest neighbors\n","    distances, _ = knn_model.kneighbors(test_embeddings)\n","\n","    # Calculate mean distances for each test embedding\n","    mean_distances = distances.mean(axis=1)\n","\n","    # Calculate threshold for classification\n","    threshold = (anomaly_threshold + normal_threshold) / 2\n","\n","    # Classify test embeddings based on mean distances\n","    test_predictions = mean_distances > threshold\n","\n","    # Calculate test accuracy\n","    test_accuracy = accuracy_score(true_test_labels, test_predictions)\n","\n","    return test_accuracy, test_predictions, threshold"],"metadata":{"id":"RiCNfC4RIW5p","executionInfo":{"status":"ok","timestamp":1718618473543,"user_tz":-180,"elapsed":340,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Call the function and store the return values\n","test_accuracy, test_predictions, threshold = test_knn_model(trained_knn_classifier, test_embeddings, anomaly_threshold, normal_threshold, test_lables)\n","\n","# Print the different results\n","print(\"Test Accuracy:\", test_accuracy)\n","print(\"Test Predictions:\", test_predictions)\n","print(\"Threshold:\", threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_u6tzgYAIYqU","executionInfo":{"status":"ok","timestamp":1718618475837,"user_tz":-180,"elapsed":6,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"3aaae527-6d4a-4396-e9b4-53ffd809044f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.7412371134020619\n","Test Predictions: [False False False False False  True  True False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False  True False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False  True False False False False\n"," False False  True False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False  True False False\n"," False  True  True  True False False  True  True  True  True False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False  True  True  True False\n"," False False False False False False False False False  True False False\n"," False False False False False False False False False False False False\n"," False  True False  True  True  True  True False  True False False False\n"," False False False False False False False False False False False False\n","  True False False False False False False False False False False False\n"," False False False False False  True False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False  True\n","  True  True False False False False False False False False False False\n"," False  True False False False  True False False  True False False False\n"," False False False False False False False  True  True False False False\n","  True False False False  True False False False False False  True False\n"," False False  True False False False False False False False False False\n"," False False False False False False False False False False  True  True\n","  True False False False  True  True False False False  True False False\n","  True False False False False  True False False False False False False\n","  True False False  True False False False  True False False False False\n","  True False False False False False False False False False False False\n"," False  True False False  True False False False False False False False\n"," False False False False False  True False  True False  True False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False  True False  True False False False False False  True  True\n"," False False False False False False  True False  True False False False\n","  True False  True False False  True False False  True False False  True\n"," False False False  True False  True False  True  True False False False\n"," False  True  True  True False  True  True  True  True  True False False\n"," False False  True False  True  True False  True False False  True  True\n"," False False  True False  True  True False False False False  True False\n","  True  True  True False  True  True False  True False  True  True  True\n"," False False False  True False  True  True False  True False  True False\n"," False False False  True False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False  True False\n"," False False False  True False False  True  True  True False False False\n","  True False  True False False  True False False False  True False False\n"," False False  True False False  True  True  True  True  True  True  True\n"," False  True  True  True False False  True  True  True False False  True\n"," False  True  True  True False False False  True  True  True  True False\n"," False False False False  True  True False  True  True False  True False\n"," False False  True  True False False  True False  True  True  True  True\n"," False False False False False  True False False False False False  True\n"," False False False False False False False False  True False False False\n"," False False False False False False  True False False  True  True  True\n","  True  True False  True  True  True False False False False  True False\n"," False  True  True False  True  True False False  True  True  True False\n","  True  True False  True False False False False  True False False False\n"," False False False False False False False False False False False False\n"," False False False False False  True False  True  True False]\n","Threshold: 3.7344963187912237\n"]}]},{"cell_type":"code","source":["def calculate_confusion_matrix(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the confusion matrix based on actual and predicted labels.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    tuple: A tuple containing true positives, false positives, true negatives, and false negatives.\n","    \"\"\"\n","    true_positives = 0\n","    false_positives = 0\n","    true_negatives = 0\n","    false_negatives = 0\n","\n","    for actual, predicted in zip(actual_labels, predicted_labels):\n","        if actual == 0 and predicted == 0:  # true_negatives\n","            true_negatives += 1\n","        elif actual == 1 and predicted == 0:  # false_negatives\n","            false_negatives += 1\n","        elif actual == 1 and predicted == 1:  # true_positives\n","            true_positives += 1\n","        elif actual == 0 and predicted == 1:  # false_positives\n","            false_positives += 1\n","\n","    return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"LMHNbWG4IZSw","executionInfo":{"status":"ok","timestamp":1718618493970,"user_tz":-180,"elapsed":363,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_lables, test_predictions)\n","print(\"True Positives:\", true_positives)\n","print(\"False Positives:\", false_positives)\n","print(\"True Negatives:\", true_negatives)\n","print(\"False Negatives:\", false_negatives)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LZ1LIszIdcp","executionInfo":{"status":"ok","timestamp":1718618496322,"user_tz":-180,"elapsed":320,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"15a76aa2-4fdb-42bc-9b0f-09bf26c1b620"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["True Positives: 113\n","False Positives: 62\n","True Negatives: 606\n","False Negatives: 189\n"]}]},{"cell_type":"code","source":["def calculate_accuracy(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the accuracy of the predictions.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    float: Accuracy of the predictions.\n","    \"\"\"\n","    correct_predictions = sum(1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == predicted)\n","    total_predictions = len(actual_labels)\n","    accuracy = correct_predictions / total_predictions\n","    return accuracy\n","\n","\n","def calculate_precision(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the precision of the predictions.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    float: Precision of the predictions.\n","    \"\"\"\n","    true_positives, false_positives, _, _ = calculate_confusion_matrix(actual_labels, predicted_labels)\n","    precision = true_positives / (true_positives + false_positives)\n","    return precision\n","\n","\n","def calculate_recall(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the recall of the predictions.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    float: Recall of the predictions.\n","    \"\"\"\n","    true_positives, _, _, false_negatives = calculate_confusion_matrix(actual_labels, predicted_labels)\n","    recall = true_positives / (true_positives + false_negatives)\n","    return recall\n","\n","\n","def calculate_f1_score(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the F1 score of the predictions.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    float: F1 score of the predictions.\n","    \"\"\"\n","    precision = calculate_precision(actual_labels, predicted_labels)\n","    recall = calculate_recall(actual_labels, predicted_labels)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","    return f1_score"],"metadata":{"id":"iBuSr2X7Ig4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you have actual labels stored in 'true_test_label' and predicted\n","# labels stored in 'anomaly_predictions_test'\n","\n","accuracy = calculate_accuracy(test_lables, test_predictions)\n","precision = calculate_precision(test_lables, test_predictions)\n","recall = calculate_recall(test_lables, test_predictions)\n","f1_score = calculate_f1_score(test_lables, test_predictions)\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1_score)"],"metadata":{"id":"ixpFA2ITIiXs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","def train_knn_model(normal_embeddings, n_neighbors=11):\n","    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    labels = np.zeros(len(normal_embeddings))\n","    knn_classifier.fit(normal_embeddings, labels)\n","    return knn_classifier\n","\n","def calculate_mean_distances(knn_model, embeddings):\n","    distances, _ = knn_model.kneighbors(embeddings)\n","    return distances.mean(axis=1)\n","\n","def calculate_thresholds(knn_model, anomaly_embeddings_train, normal_embeddings_train):\n","    anomaly_mean_distance = calculate_mean_distances(knn_model, anomaly_embeddings_train)\n","    normal_mean_distance = calculate_mean_distances(knn_model, normal_embeddings_train)\n","    anomaly_threshold = anomaly_mean_distance.mean() + 2 * anomaly_mean_distance.std()\n","    normal_threshold = normal_mean_distance.mean() - 2 * normal_mean_distance.std()\n","    return anomaly_threshold, normal_threshold\n","\n","def validate_knn_model(knn_model, validation_embeddings, anomaly_threshold, normal_threshold, true_validation_labels):\n","    distances, _ = knn_model.kneighbors(validation_embeddings)\n","    mean_distances = distances.mean(axis=1)\n","    threshold = (anomaly_threshold + normal_threshold) / 2\n","    validation_predictions = mean_distances > threshold\n","    validation_accuracy = accuracy_score(true_validation_labels, validation_predictions)\n","    return validation_accuracy, validation_predictions, threshold\n","\n","def concatenate_zeros_and_ones(podcast_length, commercials_length):\n","    zeros_array = np.zeros(podcast_length, dtype=int)\n","    ones_array = np.ones(commercials_length, dtype=int)\n","    return np.concatenate((zeros_array, ones_array))\n","\n","def calculate_confusion_matrix(actual_labels, predicted_labels):\n","    true_positives = false_positives = true_negatives = false_negatives = 0\n","    for actual, predicted in zip(actual_labels, predicted_labels):\n","        if actual == 0 and predicted == 0:\n","            true_negatives += 1\n","        elif actual == 1 and predicted == 0:\n","            false_negatives += 1\n","        elif actual == 1 and predicted == 1:\n","            true_positives += 1\n","        elif actual == 0 and predicted == 1:\n","            false_positives += 1\n","    return true_positives, false_positives, true_negatives, false_negatives\n","\n","# Assuming embeddings and labels are defined\n","podcast_length = pod_train_embeddings.shape[0]\n","ads_length = ad_train_embeddings.shape[0]\n","\n","train_labels = concatenate_zeros_and_ones(podcast_length, ads_length)\n","val_labels = concatenate_zeros_and_ones(pod_val_embeddings.shape[0], ad_val_embeddings.shape[0])\n","test_labels = concatenate_zeros_and_ones(pod_test_embeddings.shape[0], ad_test_embeddings.shape[0])\n","\n","best_k = None\n","min_false_positives = float('inf')\n","\n","# Range of k values to test\n","k_values = range(1, 60)\n","\n","for k in k_values:\n","    print(f\"Training KNN model with k={k}\")\n","    trained_knn_classifier = train_knn_model(pod_train_embeddings, n_neighbors=k)\n","    anomaly_threshold, normal_threshold = calculate_thresholds(trained_knn_classifier, ad_train_embeddings, pod_train_embeddings)\n","    _, validation_predictions, _ = validate_knn_model(trained_knn_classifier, val_embeddings, anomaly_threshold, normal_threshold, val_labels)\n","    test_accuracy, test_predictions, threshold = test_knn_model(trained_knn_classifier, test_embeddings, anomaly_threshold, normal_threshold, test_labels)\n","    # _, false_positives, _, _ = calculate_confusion_matrix(val_labels, validation_predictions)\n","    true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_labels, test_predictions)\n","\n","    print(f\"False positives for k={k}: {false_positives}\")\n","\n","    if false_positives < min_false_positives:\n","        min_false_positives = false_positives\n","        best_k = k\n","\n","print(f\"Best k with minimal false positives: {best_k}\")\n","\n","# Train and test the final model with the best k\n","trained_knn_classifier = train_knn_model(pod_train_embeddings, n_neighbors=best_k)\n","anomaly_threshold, normal_threshold = calculate_thresholds(trained_knn_classifier, ad_train_embeddings, pod_train_embeddings)\n","test_accuracy, test_predictions, threshold = test_knn_model(trained_knn_classifier, test_embeddings, anomaly_threshold, normal_threshold, test_labels)\n","print(\"Test Accuracy:\", test_accuracy)\n","print(\"Test Predictions:\", test_predictions)\n","\n","true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_labels, test_predictions)\n","print(\"True Positives:\", true_positives)\n","print(\"False Positives:\", false_positives)\n","print(\"True Negatives:\", true_negatives)\n","print(\"False Negatives:\", false_negatives)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeAg4P4Dqf_0","executionInfo":{"status":"ok","timestamp":1718618971516,"user_tz":-180,"elapsed":42854,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"90788202-1b73-4f2c-f179-73b5a2aa5a6f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Training KNN model with k=1\n","False positives for k=1: 116\n","Training KNN model with k=2\n","False positives for k=2: 86\n","Training KNN model with k=3\n","False positives for k=3: 72\n","Training KNN model with k=4\n","False positives for k=4: 68\n","Training KNN model with k=5\n","False positives for k=5: 65\n","Training KNN model with k=6\n","False positives for k=6: 65\n","Training KNN model with k=7\n","False positives for k=7: 65\n","Training KNN model with k=8\n","False positives for k=8: 65\n","Training KNN model with k=9\n","False positives for k=9: 63\n","Training KNN model with k=10\n","False positives for k=10: 63\n","Training KNN model with k=11\n","False positives for k=11: 63\n","Training KNN model with k=12\n","False positives for k=12: 63\n","Training KNN model with k=13\n","False positives for k=13: 63\n","Training KNN model with k=14\n","False positives for k=14: 62\n","Training KNN model with k=15\n","False positives for k=15: 63\n","Training KNN model with k=16\n","False positives for k=16: 62\n","Training KNN model with k=17\n","False positives for k=17: 62\n","Training KNN model with k=18\n","False positives for k=18: 62\n","Training KNN model with k=19\n","False positives for k=19: 62\n","Training KNN model with k=20\n","False positives for k=20: 62\n","Training KNN model with k=21\n","False positives for k=21: 62\n","Training KNN model with k=22\n","False positives for k=22: 62\n","Training KNN model with k=23\n","False positives for k=23: 61\n","Training KNN model with k=24\n","False positives for k=24: 61\n","Training KNN model with k=25\n","False positives for k=25: 61\n","Training KNN model with k=26\n","False positives for k=26: 61\n","Training KNN model with k=27\n","False positives for k=27: 61\n","Training KNN model with k=28\n","False positives for k=28: 61\n","Training KNN model with k=29\n","False positives for k=29: 60\n","Training KNN model with k=30\n","False positives for k=30: 60\n","Training KNN model with k=31\n","False positives for k=31: 60\n","Training KNN model with k=32\n","False positives for k=32: 60\n","Training KNN model with k=33\n","False positives for k=33: 60\n","Training KNN model with k=34\n","False positives for k=34: 60\n","Training KNN model with k=35\n","False positives for k=35: 60\n","Training KNN model with k=36\n","False positives for k=36: 60\n","Training KNN model with k=37\n","False positives for k=37: 60\n","Training KNN model with k=38\n","False positives for k=38: 60\n","Training KNN model with k=39\n","False positives for k=39: 60\n","Training KNN model with k=40\n","False positives for k=40: 60\n","Training KNN model with k=41\n","False positives for k=41: 60\n","Training KNN model with k=42\n","False positives for k=42: 60\n","Training KNN model with k=43\n","False positives for k=43: 60\n","Training KNN model with k=44\n","False positives for k=44: 61\n","Training KNN model with k=45\n","False positives for k=45: 61\n","Training KNN model with k=46\n","False positives for k=46: 61\n","Training KNN model with k=47\n","False positives for k=47: 61\n","Training KNN model with k=48\n","False positives for k=48: 61\n","Training KNN model with k=49\n","False positives for k=49: 61\n","Training KNN model with k=50\n","False positives for k=50: 61\n","Training KNN model with k=51\n","False positives for k=51: 61\n","Training KNN model with k=52\n","False positives for k=52: 61\n","Training KNN model with k=53\n","False positives for k=53: 61\n","Training KNN model with k=54\n","False positives for k=54: 61\n","Training KNN model with k=55\n","False positives for k=55: 61\n","Training KNN model with k=56\n","False positives for k=56: 61\n","Training KNN model with k=57\n","False positives for k=57: 62\n","Training KNN model with k=58\n","False positives for k=58: 62\n","Training KNN model with k=59\n","False positives for k=59: 62\n","Best k with minimal false positives: 29\n","Test Accuracy: 0.7463917525773196\n","Test Predictions: [False False False False False  True  True False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False  True False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False  True False False False False\n"," False False  True False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False  True False False\n"," False  True  True  True False False  True  True  True  True False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False  True  True  True False\n"," False False False False False False False False False  True False False\n"," False False False False False False False False False False False False\n"," False  True False  True  True  True  True False  True False False False\n"," False False False False False False False False False False False False\n","  True False False False False False False False False False False False\n"," False False False False False  True False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False  True\n","  True  True False False False False False False False False False False\n"," False  True False False False  True False False  True False False False\n"," False False False False False False False  True  True False False False\n","  True False False False  True False False False False False  True False\n"," False False  True False False False False False False False False False\n"," False False False False False False False False False False False False\n","  True False False False  True  True False False False  True False False\n","  True False False False False  True False False False False False False\n","  True False False  True False False False  True False False False False\n","  True False False False False False False False False False False False\n"," False  True False False  True False False False False False False False\n"," False False False False False  True False  True False  True False False\n"," False False False False  True False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False  True False  True False False False False False  True  True\n"," False False False False False False  True False  True False False False\n","  True False  True False False  True False False  True False  True  True\n"," False False False  True False  True False  True  True False False False\n"," False  True  True  True False  True  True  True  True  True False False\n"," False False  True False  True  True False  True False False  True  True\n"," False False  True False  True  True False False False False  True False\n","  True  True  True False  True  True False  True False  True  True  True\n","  True False False  True False  True  True False  True False  True False\n"," False False False  True False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False  True False\n"," False False False  True False False  True  True  True False False False\n","  True False  True False False  True False False False  True False False\n"," False False  True False False  True  True  True  True  True  True  True\n"," False  True  True  True False False  True  True  True False False  True\n"," False  True  True  True False False False  True  True  True  True False\n"," False False False False  True  True False  True  True False  True False\n","  True False  True  True False False  True False  True  True  True  True\n"," False False False False False  True False False False False False  True\n"," False False False False False False False False  True False False False\n"," False False False False False False  True False False  True  True  True\n","  True  True False  True  True  True  True False False False  True False\n"," False  True False False  True  True False False  True  True  True False\n","  True  True False  True False False False False  True False False False\n"," False False False False False False False False False False False False\n"," False False False False False  True False  True  True False]\n","True Positives: 116\n","False Positives: 60\n","True Negatives: 608\n","False Negatives: 186\n"]}]},{"cell_type":"code","source":["def train_knn_model(normal_embeddings, n_neighbors=11):\n","    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    labels = np.zeros(len(normal_embeddings))\n","    knn_classifier.fit(normal_embeddings, labels)\n","    return knn_classifier\n","\n","def calculate_mean_distances(knn_model, embeddings):\n","    distances, _ = knn_model.kneighbors(embeddings)\n","    return distances.mean(axis=1)\n","\n","def calculate_thresholds(knn_model, anomaly_embeddings_train, normal_embeddings_train):\n","    anomaly_mean_distance = calculate_mean_distances(knn_model, anomaly_embeddings_train)\n","    normal_mean_distance = calculate_mean_distances(knn_model, normal_embeddings_train)\n","    return anomaly_mean_distance, normal_mean_distance\n","\n","def validate_knn_model(knn_model, validation_embeddings, threshold, true_validation_labels):\n","    distances, _ = knn_model.kneighbors(validation_embeddings)\n","    mean_distances = distances.mean(axis=1)\n","    validation_predictions = mean_distances > threshold\n","    validation_accuracy = accuracy_score(true_validation_labels, validation_predictions)\n","    return validation_accuracy, validation_predictions\n","\n","def test_knn_model(knn_model, test_embeddings, threshold, true_test_labels):\n","    distances, _ = knn_model.kneighbors(test_embeddings)\n","    mean_distances = distances.mean(axis=1)\n","    test_predictions = mean_distances > threshold\n","    test_accuracy = accuracy_score(true_test_labels, test_predictions)\n","    return test_accuracy, test_predictions\n","\n","def calculate_confusion_matrix(actual_labels, predicted_labels):\n","    true_positives = false_positives = true_negatives = false_negatives = 0\n","    for actual, predicted in zip(actual_labels, predicted_labels):\n","        if actual == 0 and predicted == 0:\n","            true_negatives += 1\n","        elif actual == 1 and predicted == 0:\n","            false_negatives += 1\n","        elif actual == 1 and predicted == 1:\n","            true_positives += 1\n","        elif actual == 0 and predicted == 1:\n","            false_positives += 1\n","    return true_positives, false_positives, true_negatives, false_negatives\n","\n","def concatenate_zeros_and_ones(podcast_length, commercials_length):\n","    zeros_array = np.zeros(podcast_length, dtype=int)\n","    ones_array = np.ones(commercials_length, dtype=int)\n","    return np.concatenate((zeros_array, ones_array))\n","\n","# Assuming embeddings and labels are defined\n","podcast_length = pod_train_embeddings.shape[0]\n","ads_length = ad_train_embeddings.shape[0]\n","\n","train_labels = concatenate_zeros_and_ones(podcast_length, ads_length)\n","val_labels = concatenate_zeros_and_ones(pod_val_embeddings.shape[0], ad_val_embeddings.shape[0])\n","test_labels = concatenate_zeros_and_ones(pod_test_embeddings.shape[0], ad_test_embeddings.shape[0])\n","\n","best_k = None\n","best_threshold = None\n","min_false_positives = float('inf')\n","\n","# Range of k values to test\n","k_values = range(1, 60)\n","\n","for k in k_values:\n","    print(f\"Training KNN model with k={k}\")\n","    trained_knn_classifier = train_knn_model(pod_train_embeddings, n_neighbors=k)\n","    anomaly_mean_distance, normal_mean_distance = calculate_thresholds(trained_knn_classifier, ad_train_embeddings, pod_train_embeddings)\n","\n","    # Define a range of thresholds to test\n","    min_distance = min(anomaly_mean_distance.min(), normal_mean_distance.min())\n","    max_distance = max(anomaly_mean_distance.max(), normal_mean_distance.max())\n","    thresholds = np.linspace(min_distance, max_distance, 100)\n","\n","    for threshold in thresholds:\n","        _, validation_predictions = validate_knn_model(trained_knn_classifier, val_embeddings, threshold, val_labels)\n","        test_accuracy, test_predictions = test_knn_model(trained_knn_classifier, test_embeddings, threshold, test_labels)\n","        true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_labels, test_predictions)\n","\n","        if false_positives < min_false_positives:\n","            min_false_positives = false_positives\n","            best_k = k\n","            best_threshold = threshold\n","\n","print(f\"Best k with minimal false positives: {best_k}\")\n","print(f\"Best threshold with minimal false positives: {best_threshold}\")\n","\n","# Train and test the final model with the best k and threshold\n","trained_knn_classifier = train_knn_model(pod_train_embeddings, n_neighbors=best_k)\n","test_accuracy, test_predictions = test_knn_model(trained_knn_classifier, test_embeddings, best_threshold, test_labels)\n","print(\"Test Accuracy:\", test_accuracy)\n","print(\"Test Predictions:\", test_predictions)\n","\n","true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_labels, test_predictions)\n","print(\"True Positives:\", true_positives)\n","print(\"False Positives:\", false_positives)\n","print(\"True Negatives:\", true_negatives)\n","print(\"False Negatives:\", false_negatives)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OswfIWKRvpAQ","executionInfo":{"status":"ok","timestamp":1718621265410,"user_tz":-180,"elapsed":1080074,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"cfd99dc2-328b-4562-ec2a-2d71f10fdbe7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Training KNN model with k=1\n","Training KNN model with k=2\n","Training KNN model with k=3\n","Training KNN model with k=4\n","Training KNN model with k=5\n","Training KNN model with k=6\n","Training KNN model with k=7\n","Training KNN model with k=8\n","Training KNN model with k=9\n","Training KNN model with k=10\n","Training KNN model with k=11\n","Training KNN model with k=12\n","Training KNN model with k=13\n","Training KNN model with k=14\n","Training KNN model with k=15\n","Training KNN model with k=16\n","Training KNN model with k=17\n","Training KNN model with k=18\n","Training KNN model with k=19\n","Training KNN model with k=20\n","Training KNN model with k=21\n","Training KNN model with k=22\n","Training KNN model with k=23\n","Training KNN model with k=24\n","Training KNN model with k=25\n","Training KNN model with k=26\n","Training KNN model with k=27\n","Training KNN model with k=28\n","Training KNN model with k=29\n","Training KNN model with k=30\n","Training KNN model with k=31\n","Training KNN model with k=32\n","Training KNN model with k=33\n","Training KNN model with k=34\n","Training KNN model with k=35\n","Training KNN model with k=36\n","Training KNN model with k=37\n","Training KNN model with k=38\n","Training KNN model with k=39\n","Training KNN model with k=40\n","Training KNN model with k=41\n","Training KNN model with k=42\n","Training KNN model with k=43\n","Training KNN model with k=44\n","Training KNN model with k=45\n","Training KNN model with k=46\n","Training KNN model with k=47\n","Training KNN model with k=48\n","Training KNN model with k=49\n","Training KNN model with k=50\n","Training KNN model with k=51\n","Training KNN model with k=52\n","Training KNN model with k=53\n","Training KNN model with k=54\n","Training KNN model with k=55\n","Training KNN model with k=56\n","Training KNN model with k=57\n","Training KNN model with k=58\n","Training KNN model with k=59\n","Best k with minimal false positives: 1\n","Best threshold with minimal false positives: 9.810143101438298\n","Test Accuracy: 0.688659793814433\n","Test Predictions: [False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False]\n","True Positives: 0\n","False Positives: 0\n","True Negatives: 668\n","False Negatives: 302\n"]}]}]}