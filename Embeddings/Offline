import sys
import numpy as np
from PyQt5.QtWidgets import QApplication, QMainWindow, QPushButton, QLabel, QVBoxLayout, QWidget, QFileDialog, QDialog, \
    QMessageBox
from pydub import AudioSegment
from pydub.playback import play
import joblib

from Vggish_Embeddings_Model import extract_vggish_embeddings


class AudioProcessor:
    def __init__(self, svm_model_path):
        #self.openL3_model = joblib.load(openL3_model_path)
        self.svm_model = joblib.load(svm_model_path)

    def convert_to_embeddings(self, audio_data, i):
        # Convert audio_data to embeddings using openL3
        # This function should use the openL3 model to extract embeddings
        # embeddings = self.openL3_model
        # if i == 0:
        #     return embeddings[0]
        # if i == 1:
        #     return embeddings[1]
        # if i == 2:
        #     return embeddings[2]
        embeddings = extract_vggish_embeddings(audio_data)
        return embeddings

    def detect_ads(self, audio_segment, i):
        # Convert the audio segment to numpy array
        audio_data = np.array(audio_segment.get_array_of_samples())

        # Convert audio_data to embeddings
        embedding = self.convert_to_embeddings(audio_data, i)

        # Classify embeddings using the SVM model
        prediction = self.svm_model.predict([embedding])

        # Return whether it's an ad or podcast
        return prediction == 1


class ConfirmationDialog(QDialog):
    def __init__(self, output_path):
        super().__init__()
        self.setWindowTitle("Confirmation")

        self.label = QLabel(f"Processed audio saved successfully at: {output_path}")
        self.ok_button = QPushButton("OK")
        self.ok_button.clicked.connect(self.accept)

        layout = QVBoxLayout()
        layout.addWidget(self.label)
        layout.addWidget(self.ok_button)

        self.setLayout(layout)


class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()

        self.setWindowTitle("Ad Detector")
        self.audio_processor = AudioProcessor('svm_model_vggish_5sec.pkl')

        self.label = QLabel("Upload an audio file (15 seconds)...")
        self.upload_button = QPushButton("Upload Audio")
        self.upload_button.clicked.connect(self.upload_audio)

        layout = QVBoxLayout()
        layout.addWidget(self.label)
        layout.addWidget(self.upload_button)

        container = QWidget()
        container.setLayout(layout)
        self.setCentralWidget(container)

    def upload_audio(self):
        options = QFileDialog.Options()
        options |= QFileDialog.ReadOnly
        file_path, _ = QFileDialog.getOpenFileName(self, "QFileDialog.getOpenFileName()", "",
                                                   "Audio Files (*.wav *.mp3);;All Files (*)", options=options)

        if file_path:
            self.close()
            self.process_audio(file_path)

    def process_audio(self, file_path):
        audio = AudioSegment.from_file(file_path)

        if len(audio) != 15000:
            self.label.setText("Please upload a 15-second audio file.")
            return

        segments = [audio[i:i + 5000] for i in range(0, len(audio), 5000)]
        processed_audio = AudioSegment.silent(duration=0)

        for i, segment in enumerate(segments):
            if self.audio_processor.detect_ads(segment, i):
                # Append silent segment if ad is detected
                processed_audio += AudioSegment.silent(duration=len(segment))
                continue
            else:
                # Append the original segment if podcast is detected
                processed_audio += segment

        output_path = "processed_audio.wav"
        processed_audio.export(output_path, format="wav")

        self.label.setText("Processing complete.")
        confirmation_dialog = ConfirmationDialog(output_path)
        confirmation_dialog.exec_()

        play(processed_audio)

    def closeEvent(self, event):
        super().closeEvent(event)


app = QApplication(sys.argv)
window = MainWindow()
window.show()
sys.exit(app.exec_())
