{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BXtv4qFfr1EdEYJuh5cjSoaZWU1mPgdi","timestamp":1716049301575}],"authorship_tag":"ABX9TyPOF0eLV/zOu6ewSwcKazv3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ***Establishing Connection to Google Drive***\n","\n","To initiate the project, the primary step entails establishing a seamless connection to Google Drive. This connection is pivotal for accessing and utilizing the requisite files and datasets essential for the project's execution."],"metadata":{"id":"hWRnEIdjf-CE"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Xo8tAgGXaRRX","colab":{"base_uri":"https://localhost:8080/","height":304},"executionInfo":{"status":"error","timestamp":1719905701033,"user_tz":-180,"elapsed":6037,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"84fa01cf-0d00-49d9-e26d-2c561028b878"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# ***Importing Essential Libraries***\n","\n","Following the establishment of the Google Drive connection, the subsequent step involves importing the essential libraries necessary for executing the code. These libraries serve as the foundational framework, providing the functionality and tools required to implement various tasks and analyses within the project."],"metadata":{"id":"mpzFJxU5gWAN"}},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"dwh8-RtGgN1C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***Loading Data for Processing and Testing***\n","\n","In this pivotal stage, we load all pertinent data into the project environment for comprehensive processing and testing. By importing the datasets integral to our analysis, we ensure a robust foundation for conducting experiments and evaluations crucial to the project's objectives."],"metadata":{"id":"krIXm9ulgvv3"}},{"cell_type":"code","source":["# for 5 second vggish\n","pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_train_embeddings.npy\")[:502, :]\n","ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_train_embeddings.npy\")\n","\n","pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_val_embeddings.npy\")\n","ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_val_embeddings.npy\")\n","\n","pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_test_embeddings.npy\")\n","ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_test_embeddings.npy\")\n","\n","# for 10 second vggish\n","# pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_pod_train_embeddings.npy\")\n","# ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_ad_train_embeddings.npy\")\n","\n","# pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_pod_val_embeddings.npy\")\n","# ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_ad_val_embeddings.npy\")\n","\n","# pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_pod_test_embeddings.npy\")\n","# ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_10sec/vggish_10sec_ad_test_embeddings.npy\")"],"metadata":{"id":"BeNNlSALg6v5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pod_train_embeddings.shape)\n","print(ad_train_embeddings.shape)\n","\n","print(pod_val_embeddings.shape)\n","print(ad_val_embeddings.shape)\n","\n","print(pod_test_embeddings.shape)\n","print(ad_test_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wv6hST6zG5Ly","executionInfo":{"status":"ok","timestamp":1717322512256,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"616f66bb-094c-4189-dae7-a3453486b14d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(502, 23552)\n","(502, 23552)\n","(410, 23552)\n","(62, 23552)\n","(412, 23552)\n","(64, 23552)\n"]}]},{"cell_type":"code","source":["# def flatten_3d_array(arr):\n","#     # Check if input is a numpy array\n","#     if isinstance(arr, np.ndarray):\n","#         # Flatten each 2D matrix and stack them horizontally\n","#         return np.hstack([matrix.flatten() for matrix in arr])\n","#     else:\n","#         # Flatten each 2D matrix and stack them horizontally\n","#         return [matrix.flatten() for matrix in arr]\n","\n","\n","# def convert_to_2d_array(three_d_array):\n","#     # Get the depth of the input array\n","#     depth = three_d_array.shape[0]\n","\n","#     # Initialize an empty list to store the converted matrices\n","#     two_d_matrices = []\n","\n","#     # Iterate over each matrix in the 3D array\n","#     for i in range(depth):\n","#         # Convert the 2D matrix to a 1D array using flatten()\n","#         one_d_array = three_d_array[i].flatten()\n","#         # Append the 1D array to the list of converted matrices\n","#         two_d_matrices.append(one_d_array)\n","\n","#     # Convert the list of 1D arrays to a 2D array\n","#     two_d_array = np.array(two_d_matrices)\n","\n","#     return two_d_array"],"metadata":{"id":"3vTe_j8v2yOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def convert_to_2d_array(three_d_array):\n","#     # Get the dimensions of the input array\n","#     depth, rows, cols = three_d_array.shape\n","\n","#     # Reshape each 2D array to 1D and concatenate them\n","#     flattened_arrays = [matrix.flatten() for matrix in three_d_array]\n","#     two_d_array = np.vstack(flattened_arrays)\n","\n","#     return two_d_array"],"metadata":{"id":"9RVOnUEhRwkt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# temp_array = convert_to_2d_array(pod_train_embeddings)\n","# print(temp_array.shape)\n","# print(temp_array)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"oW8svErORyXM","executionInfo":{"status":"error","timestamp":1716051865247,"user_tz":-180,"elapsed":268,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"5117cccc-417e-4d65-b0c0-2f72b0fa484d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"not enough values to unpack (expected 3, got 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-16cd76045124>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_2d_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpod_train_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-61f61449f819>\u001b[0m in \u001b[0;36mconvert_to_2d_array\u001b[0;34m(three_d_array)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_2d_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthree_d_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Get the dimensions of the input array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthree_d_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Reshape each 2D array to 1D and concatenate them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"]}]},{"cell_type":"code","source":["#pod_train_embeddings = convert_to_2d_array(pod_train_embeddings)\n","#ad_train_embeddings = convert_to_2d_array(ad_train_embeddings)\n","\n","# pod_val_embeddings = convert_to_2d_array(pod_val_embeddings)\n","#ad_val_embeddings = convert_to_2d_array(ad_val_embeddings)\n","\n","#pod_test_embeddings =  convert_to_2d_array(pod_test_embeddings)\n","#ad_test_embeddings = convert_to_2d_array(ad_test_embeddings)\n","\n","# print(pod_train_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxzCMN-U0RpN","executionInfo":{"status":"ok","timestamp":1716052206570,"user_tz":-180,"elapsed":297,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"29f3b61a-f2f1-495e-b193-805f66bd8900"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.6015832  2.1339035  2.3801048  ... 1.155305   2.496811   2.4857183 ]\n"," [2.4308376  2.2231705  2.4176931  ... 1.4453753  2.4609313  2.0434253 ]\n"," [2.642793   2.1048815  2.3984842  ... 1.3341454  2.0593255  2.4852192 ]\n"," ...\n"," [2.4308376  1.572939   2.7645292  ... 0.84722906 2.7093196  3.7201445 ]\n"," [2.946318   1.4554709  2.6735175  ... 1.3773403  2.6163485  3.4445045 ]\n"," [3.2203982  1.6526159  2.9299147  ... 2.1343074  3.1267385  3.0143993 ]]\n"]}]},{"cell_type":"code","source":["train_embeddings = np.concatenate((pod_train_embeddings, ad_train_embeddings))\n","val_embeddings = np.concatenate((pod_val_embeddings, ad_val_embeddings))\n","test_embeddings = np.concatenate((pod_test_embeddings, ad_test_embeddings))"],"metadata":{"id":"324_E2U5PRcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def concatenate_zeros_and_ones(podcast_length, commercials_length):\n","    # Create array of zeros with size of podcast array\n","    zeros_array = np.zeros(podcast_length, dtype=int)\n","\n","    # Create array of ones with size of commercials array\n","    ones_array = np.ones(commercials_length, dtype=int)\n","\n","    # Concatenate arrays\n","    concatenated_array = np.concatenate((zeros_array, ones_array))\n","\n","    return concatenated_array\n","\n","\n","podcast_length = pod_train_embeddings.shape[0]\n","ads_length = ad_train_embeddings.shape[0]\n"],"metadata":{"id":"OOZ2JXVTFGh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_labels = concatenate_zeros_and_ones(pod_train_embeddings.shape[0], ad_train_embeddings.shape[0])\n","val_labels = concatenate_zeros_and_ones(pod_val_embeddings.shape[0], ad_val_embeddings.shape[0])\n","test_lables = concatenate_zeros_and_ones(pod_test_embeddings.shape[0], ad_test_embeddings.shape[0])"],"metadata":{"id":"6pYpPL66TBtE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***Training Support Vector Machine (SVM) Model***\n","\n","In this critical phase, we commence the training process for our SVM model by executing the data allocated to the training set. Prior to this, we crafted a function designed to furnish us with the requisite model. Subsequently, invoking this function enables us to obtain the model tailored to our specifications, facilitating the subsequent stages of our analysis."],"metadata":{"id":"i15jPuVcg6bk"}},{"cell_type":"code","source":["# Define sample weights\n","# Assuming you have a binary classification problem with labels 0 (podcast) and 1 (commercial)\n","# Assign weight 1 to podcast samples and weight 6 to commercial samples\n","sample_weights = {0: 1, 1: 1}\n","\n","def train_svm_model(embeddings, labels, weights=None):\n","    \"\"\"\n","    Train an SVM model using the provided embeddings and labels.\n","\n","    Parameters:\n","    - embeddings: List of embeddings (list of arrays).\n","    - labels: List of corresponding labels.\n","    - weights: Dictionary specifying the class weights. Default is None.\n","\n","    Returns:\n","    - model: Trained SVM model.\n","    \"\"\"\n","    # Initialize SVM model with linear kernel and class weights\n","    model = SVC(kernel='linear', class_weight=weights)\n","    # Train the model\n","    model.fit(embeddings, labels)\n","    return model\n"],"metadata":{"id":"nwa0gp74iYBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the SVM model with sample weights\n","model = train_svm_model(train_embeddings, train_labels, weights=sample_weights)"],"metadata":{"id":"_aKlu7ozjh_t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***Model Validation and Adjustment***\n","\n","In this pivotal stage, we evaluate the performance of our model by running the data assigned to the validation set. This step enables us to conduct a thorough examination of the model's efficacy and identify any necessary adjustments. By scrutinizing the model's performance against validation data, we iteratively refine its parameters to enhance its accuracy and robustness."],"metadata":{"id":"ec3TLa0fkSku"}},{"cell_type":"code","source":["def validate_model(model, val_embeddings, val_labels):\n","    \"\"\"\n","    Validate the trained model on a validation set.\n","\n","    Parameters:\n","    - model: Trained machine learning model.\n","    - val_embeddings: Embeddings of the validation set.\n","    - val_labels: Labels of the validation set.\n","\n","    Returns:\n","    - validation_accuracy: Accuracy of the model on the validation set.\n","    - predicted_labels: Predicted labels for the validation set.\n","    - actual_labels: Actual labels of the validation set.\n","    \"\"\"\n","    # Make predictions on the validation set\n","    val_predictions = model.predict(val_embeddings)\n","\n","    # Calculate validation accuracy\n","    validation_accuracy = accuracy_score(val_labels, val_predictions)\n","\n","    # Print validation accuracy\n","    print(\"Validation Accuracy:\", validation_accuracy)\n","\n","    # Print predicted and actual labels for inspection\n","    print(\"Predicted labels:\")\n","    print(val_predictions)\n","    print(\"Actual labels:\")\n","    print(val_labels)\n","\n","    # Return validation accuracy and predicted/actual labels\n","    return validation_accuracy, val_predictions, val_labels"],"metadata":{"id":"vIl-Vofglnc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function by passing the required arguments\n","validation_accuracy, validation_predicted_labels, validation_actual_labels = validate_model(model, val_embeddings, val_labels)\n","\n","# Now you can use the returned values as needed\n","print(\"Validation Accuracy:\", validation_accuracy)"],"metadata":{"id":"QfmflMtcl8Tj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717322563579,"user_tz":-180,"elapsed":1353,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"a1f44d20-7d2c-4953-d718-ea1c96642ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 1.0\n","Predicted labels:\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","Actual labels:\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","Validation Accuracy: 1.0\n"]}]},{"cell_type":"markdown","source":["# ***Final Model Evaluation with Test Data***\n","\n","In this culminating phase, we subject the test data to our final model for comprehensive evaluation of its performance on real-world datasets. This step allows us to ascertain the effectiveness and generalizability of our model beyond the training and validation stages. By rigorously scrutinizing the model's performance against unseen data, we derive insights into its real-world applicability and overall efficacy."],"metadata":{"id":"atj5XNm7mzA2"}},{"cell_type":"code","source":["def test_model(model, test_embeddings, test_labels):\n","    \"\"\"\n","    Test the trained model on a separate test dataset.\n","\n","    Parameters:\n","    - model: Trained machine learning model.\n","    - test_embeddings: Embeddings of the test dataset.\n","    - test_labels: Labels of the test dataset.\n","\n","    Returns:\n","    - test_accuracy: Accuracy of the model on the test dataset.\n","    - predicted_labels: Predicted labels for the test dataset.\n","    - actual_labels: Actual labels of the test dataset.\n","    \"\"\"\n","    # Make predictions on the test dataset\n","    predicted_labels = model.predict(test_embeddings)\n","\n","    # Calculate test accuracy\n","    test_accuracy = accuracy_score(test_labels, predicted_labels)\n","\n","    # Print test accuracy\n","    print(\"Test Accuracy:\", test_accuracy)\n","\n","    # Print predicted and actual labels for inspection\n","    print(\"Predicted labels:\")\n","    print(predicted_labels)\n","    print(\"Actual labels:\")\n","    print(test_labels)\n","\n","    # Return test accuracy and predicted/actual labels\n","    return test_accuracy, predicted_labels, test_labels"],"metadata":{"id":"BhCCA_9EmzkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function by passing the required arguments\n","test_accuracy, test_predicted_labels, test_actual_labels = test_model(model, test_embeddings, test_lables)\n","\n","# Now you can use the returned values as needed\n","print(\"Test Accuracy:\", test_accuracy)"],"metadata":{"id":"sVlxu6bSmz4E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717322577493,"user_tz":-180,"elapsed":1620,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"4326556d-c18d-4e76-b293-6b41dda4c1bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 1.0\n","Predicted labels:\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","Actual labels:\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","Test Accuracy: 1.0\n"]}]},{"cell_type":"markdown","source":["# ***Presentation of Model Evaluation Metrics***\n","\n","In this critical juncture, we showcase a comprehensive array of evaluation metrics meticulously designed to gauge the efficacy and performance of our model. Through the presentation of these metrics, including but not limited to accuracy, precision, recall, and F1-score, we offer a nuanced understanding of the model's strengths and limitations. This holistic evaluation serves to validate the model's efficacy and aids in informing future iterations or enhancements."],"metadata":{"id":"ue7E5rs_oZDb"}},{"cell_type":"code","source":["# def calculate_confusion_matrix(actual_labels, predicted_labels):\n","#     \"\"\"\n","#     Calculate the confusion matrix metrics.\n","\n","#     Parameters:\n","#     - actual_labels: Actual labels.\n","#     - predicted_labels: Predicted labels.\n","\n","#     Returns:\n","#     - true_positives: Number of true positives.\n","#     - false_positives: Number of false positives.\n","#     - true_negatives: Number of true negatives.\n","#     - false_negatives: Number of false negatives.\n","#     \"\"\"\n","#     true_positives = 0\n","#     false_positives = 0\n","#     true_negatives = 0\n","#     false_negatives = 0\n","\n","#     for actual, predicted in zip(actual_labels, predicted_labels):\n","#         if actual == 0:\n","#             if predicted == 0:\n","#                 true_positives += 1\n","#             else:\n","#                 false_negatives += 1\n","#         else:\n","#             if predicted == 0:\n","#                 false_positives += 1\n","#             else:\n","#                 true_negatives += 1\n","\n","#     return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"AdhOhJa6oZZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_confusion_matrix(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the confusion matrix based on actual and predicted labels.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    tuple: A tuple containing true positives, false positives, true negatives, and false negatives.\n","    \"\"\"\n","    true_positives = 0\n","    false_positives = 0\n","    true_negatives = 0\n","    false_negatives = 0\n","\n","    for actual, predicted in zip(actual_labels, predicted_labels):\n","        if actual == 0 and predicted == 0:  # true_negatives\n","            true_negatives += 1\n","        elif actual == 1 and predicted == 0:  # false_negatives\n","            false_negatives += 1\n","        elif actual == 1 and predicted == 1:  # true_positives\n","            true_positives += 1\n","        elif actual == 0 and predicted == 1:  # false_positives\n","            false_positives += 1\n","\n","    return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"iJ4YGi-kOhOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def calculate_confusion_matrix(actual_labels, predicted_labels):\n","#     tp = sum([1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == 0 and predicted == 0])\n","#     fn = sum([1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == 0 and predicted != 0])\n","#     fp = sum([1 for actual, predicted in zip(actual_labels, predicted_labels) if actual != 0 and predicted == 0])\n","#     tn = sum([1 for actual, predicted in zip(actual_labels, predicted_labels) if actual != 0 and predicted != 0])\n","#     return tp, fn, fp, tn"],"metadata":{"id":"wtxHu5NkOTA7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call the function by passing the actual labels and predicted labels\n","true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_lables, test_predicted_labels)\n","\n","# Print the results\n","print(\"True Positives:\", true_positives)\n","print(\"False Positives:\", false_positives)\n","print(\"True Negatives:\", true_negatives)\n","print(\"False Negatives:\", false_negatives)\n","\n","# Calculate evaluation values\n","precision = true_positives / (true_positives + false_positives)\n","recall = true_positives / (true_positives + false_negatives)\n","specificity = true_negatives / (true_negatives + false_positives)\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","# Print the evaluation values\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"Specificity:\", specificity)\n","print(\"F1 Score:\", f1_score)"],"metadata":{"id":"rxz6rG_boZOj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717322601972,"user_tz":-180,"elapsed":424,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"9c34c4c5-5b84-4482-c528-c29b6ce34ecf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True Positives: 64\n","False Positives: 0\n","True Negatives: 412\n","False Negatives: 0\n","Precision: 1.0\n","Recall: 1.0\n","Specificity: 1.0\n","F1 Score: 1.0\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","# Save the trained model to a file\n","joblib_file = \"svm_model.pkl\"\n","joblib.dump(model, joblib_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_TUWmX3Z2MU","executionInfo":{"status":"ok","timestamp":1717322667104,"user_tz":-180,"elapsed":431,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"65ecb1df-a6f4-46bd-b12f-9407a42a97f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['svm_model.pkl']"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["from google.colab import files\n","\n","# Download the file\n","files.download(joblib_file)"],"metadata":{"id":"LwXQ8LwhaBUb","executionInfo":{"status":"ok","timestamp":1717322670468,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ariel Erusalimsky","userId":"09307154366084279372"}},"outputId":"6c7773fb-1b8e-410a-f485-cfe801031db2","colab":{"base_uri":"https://localhost:8080/","height":34}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a8071986-eb26-4895-9981-7781a4fe3c08\", \"svm_model.pkl\", 31470459)"]},"metadata":{}}]}]}