{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ***Establishing Connection to Google Drive***\n","\n","To initiate the project, the primary step entails establishing a seamless connection to Google Drive. This connection is pivotal for accessing and utilizing the requisite files and datasets essential for the project's execution."],"metadata":{"id":"Cm5hX9pkp6mE"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"FXYVQFTWpnqk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720345471692,"user_tz":-180,"elapsed":25583,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"672f43d1-8b7d-4be8-8327-94303b369828"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# ***Importing Essential Libraries***\n","\n","Following the establishment of the Google Drive connection, the subsequent step involves importing the essential libraries necessary for executing the code. These libraries serve as the foundational framework, providing the functionality and tools required to implement various tasks and analyses within the project."],"metadata":{"id":"fh0_J_nBp-WZ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"4cuMg6X6SQcn"}},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n","\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"F1rDOlzfqB_I","executionInfo":{"status":"ok","timestamp":1720345473235,"user_tz":-180,"elapsed":1548,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# ***Loading Data for Processing and Testing***\n","\n","In this pivotal stage, we load all pertinent data into the project environment for comprehensive processing and testing. By importing the datasets integral to our analysis, we ensure a robust foundation for conducting experiments and evaluations crucial to the project's objectives."],"metadata":{"id":"3PLpgAhJqjRF"}},{"cell_type":"code","source":["\n","# pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_pod_train_embeddings.npy\")[:2574,:,:]\n","# ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_ad_train_embeddings.npy\")\n","\n","# pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_pod_val_embeddings.npy\")\n","# ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_ad_val_embeddings.npy\")\n","\n","# pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_pod_test_embeddings.npy\")\n","# ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_1sec/vggish_1sec_ad_test_embeddings.npy\")\n","\n","\n","\n","pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_pod_train_embeddings.npy\")\n","ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_ad_train_embeddings.npy\")\n","\n","pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_pod_val_embeddings.npy\")\n","ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_ad_val_embeddings.npy\")\n","\n","pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_pod_test_embeddings.npy\")\n","ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_3sec/vggish_3sec_ad_test_embeddings.npy\")\n","\n","\n","\n","\n","# pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_pod_train_embeddings.npy\")\n","# ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_ad_train_embeddings.npy\")\n","\n","# pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_pod_val_embeddings.npy\")\n","# ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_ad_val_embeddings.npy\")\n","\n","# pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_pod_test_embeddings.npy\")\n","# ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/vggish_5sec/vggish_5sec_ad_test_embeddings.npy\")\n","\n","\n","\n","\n","# pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_pod_train_embeddings.npy\")\n","# ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_ad_train_embeddings.npy\")\n","\n","# pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_pod_val_embeddings.npy\")\n","# ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_ad_val_embeddings.npy\")\n","\n","# pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_pod_test_embeddings.npy\")\n","# ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_1sec/OpenL3_1sec_ad_test_embeddings.npy\")\n","\n","\n","\n","# pod_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_train_embeddings.npy\")\n","# ad_train_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_train_embeddings.npy\")\n","\n","# pod_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_val_embeddings.npy\")\n","# ad_val_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_val_embeddings.npy\")\n","\n","# pod_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_pod_test_embeddings.npy\")\n","# ad_test_embeddings = np.load(\"/content/drive/MyDrive/AD-Blocker Project/embeddings/OpenL3_5sec/OpenL3_5sec_ad_test_embeddings.npy\")\n"],"metadata":{"id":"owP7Im4hqm4R","executionInfo":{"status":"ok","timestamp":1720345477039,"user_tz":-180,"elapsed":3806,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def convert_to_2d_array(three_d_array):\n","    # Get the dimensions of the input array\n","    depth, rows, cols = three_d_array.shape\n","\n","    # Reshape each 2D array to 1D and concatenate them\n","    flattened_arrays = [matrix.flatten() for matrix in three_d_array]\n","    two_d_array = np.vstack(flattened_arrays)\n","\n","    return two_d_array"],"metadata":{"id":"Ri2T72NaMYNk","executionInfo":{"status":"ok","timestamp":1720345477039,"user_tz":-180,"elapsed":5,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["pod_train_embeddings = convert_to_2d_array(pod_train_embeddings)\n","ad_train_embeddings = convert_to_2d_array(ad_train_embeddings)\n","\n","pod_val_embeddings = convert_to_2d_array(pod_val_embeddings)\n","ad_val_embeddings = convert_to_2d_array(ad_val_embeddings)\n","\n","pod_test_embeddings =  convert_to_2d_array(pod_test_embeddings)\n","ad_test_embeddings = convert_to_2d_array(ad_test_embeddings)"],"metadata":{"collapsed":true,"id":"jhyqSySRMcdz","executionInfo":{"status":"ok","timestamp":1720345477040,"user_tz":-180,"elapsed":5,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(pod_train_embeddings.shape)\n","print(ad_train_embeddings.shape)\n","\n","print(pod_val_embeddings.shape)\n","print(ad_val_embeddings.shape)\n","\n","print(pod_test_embeddings.shape)\n","print(ad_test_embeddings.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8wWvUj2M_h4","executionInfo":{"status":"ok","timestamp":1720345479730,"user_tz":-180,"elapsed":446,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"4dfc75e5-6999-4217-b1e6-51b2604ed99e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(5260, 384)\n","(852, 384)\n","(795, 384)\n","(101, 384)\n","(796, 384)\n","(103, 384)\n"]}]},{"cell_type":"code","source":["# pod_train_embeddings = pod_train_embeddings[:240, :]"],"metadata":{"id":"lG_9F3ADlZvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_embeddings = np.concatenate((pod_train_embeddings, ad_train_embeddings))\n","val_embeddings = np.concatenate((pod_val_embeddings, ad_val_embeddings))\n","test_embeddings = np.concatenate((pod_test_embeddings, ad_test_embeddings))"],"metadata":{"id":"FkW_xN98KvDa","executionInfo":{"status":"ok","timestamp":1720345482585,"user_tz":-180,"elapsed":312,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def concatenate_zeros_and_ones(podcast_length, commercials_length):\n","    # Create array of zeros with size of podcast array\n","    zeros_array = np.zeros(podcast_length, dtype=int)\n","\n","    # Create array of ones with size of commercials array\n","    ones_array = np.ones(commercials_length, dtype=int)\n","\n","    # Concatenate arrays\n","    concatenated_array = np.concatenate((zeros_array, ones_array))\n","\n","    return concatenated_array"],"metadata":{"id":"XGU329MVLzXg","executionInfo":{"status":"ok","timestamp":1720345484572,"user_tz":-180,"elapsed":284,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_labels = concatenate_zeros_and_ones(pod_train_embeddings.shape[0], ad_train_embeddings.shape[0])\n","val_labels = concatenate_zeros_and_ones(pod_val_embeddings.shape[0], ad_val_embeddings.shape[0])\n","test_labels = concatenate_zeros_and_ones(pod_test_embeddings.shape[0], ad_test_embeddings.shape[0])"],"metadata":{"id":"vFyBr74mKnQ-","executionInfo":{"status":"ok","timestamp":1720345486552,"user_tz":-180,"elapsed":303,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# ***Training Random Forest Model***\n","\n","In this critical phase, we commence the training process for our Random Forest model by executing the data allocated to the training set. Prior to this, we crafted a function designed to furnish us with the requisite model. Subsequently, invoking this function enables us to obtain the model tailored to our specifications, facilitating the subsequent stages of our analysis."],"metadata":{"id":"7Sc-yJsFrycc"}},{"cell_type":"code","source":["def train_random_forest_classifier(train_embeddings, train_labels, n_estimators=12, random_state=4):\n","    \"\"\"\n","    Train a Random Forest Classifier on the given training data.\n","\n","    Parameters:\n","    ----------\n","    - train_embeddings (array-like): Feature vectors or embeddings of the training data.\n","    - train_labels (array-like): Labels corresponding to the training data.\n","    - n_estimators (int, optional): Number of trees in the forest. Default is 20.\n","    - random_state (int, optional): Seed for random number generation. Default is 50.\n","\n","    Returns:\n","    -------\n","    - clf (RandomForestClassifier): Trained Random Forest Classifier model.\n","    \"\"\"\n","\n","    # Input validation\n","    train_embeddings, train_labels = check_X_y(train_embeddings, train_labels)\n","\n","    # Initialize Random Forest Classifier\n","    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n","\n","    # Train the classifier\n","    clf.fit(train_embeddings, train_labels)\n","\n","    return clf"],"metadata":{"id":"PGnraWcGqo2U","executionInfo":{"status":"ok","timestamp":1720345649938,"user_tz":-180,"elapsed":303,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["clf = train_random_forest_classifier(train_embeddings, train_labels)"],"metadata":{"id":"ST7GXIcxsCth","executionInfo":{"status":"ok","timestamp":1720345655837,"user_tz":-180,"elapsed":3894,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["# ***Model Validation and Adjustment***\n","\n","In this pivotal stage, we evaluate the performance of our model by running the data assigned to the validation set. This step enables us to conduct a thorough examination of the model's efficacy and identify any necessary adjustments. By scrutinizing the model's performance against validation data, we iteratively refine its parameters to enhance its accuracy and robustness."],"metadata":{"id":"0pV23QGnseRF"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","def evaluate_classifier(clf, validation_embeddings, validation_labels):\n","    \"\"\"\n","    Evaluate the trained classifier on validation data.\n","\n","    Parameters:\n","    ----------\n","    - clf (object): Trained classifier object.\n","    - validation_embeddings (array-like): Feature vectors or embeddings of the validation data.\n","    - validation_labels (array-like): Labels corresponding to the validation data.\n","\n","    Returns:\n","    -------\n","    - val_accuracy (float): Accuracy of the classifier on the validation data.\n","    \"\"\"\n","\n","    # Perform predictions on validation data\n","    val_predictions = clf.predict(validation_embeddings)\n","\n","    # Calculate validation accuracy\n","    val_accuracy = accuracy_score(validation_labels, val_predictions)\n","    #print(\"val prediction\",val_predictions)\n","    return val_accuracy"],"metadata":{"id":"0fCtAobKse9C","executionInfo":{"status":"ok","timestamp":1720345655838,"user_tz":-180,"elapsed":3,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","val_accuracy = evaluate_classifier(clf, val_embeddings, val_labels)\n","print(\"Validation Accuracy:\", val_accuracy)\n","#print(\"val labels\", val_labels)"],"metadata":{"id":"gxZHQDTTsn91","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720345656293,"user_tz":-180,"elapsed":457,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"6fbc46a4-08f3-4685-dfd2-67311a906329"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9274553571428571\n"]}]},{"cell_type":"markdown","source":["# ***Final Model Evaluation with Test Data***\n","\n","In this culminating phase, we subject the test data to our final model for comprehensive evaluation of its performance on real-world datasets. This step allows us to ascertain the effectiveness and generalizability of our model beyond the training and validation stages. By rigorously scrutinizing the model's performance against unseen data, we derive insights into its real-world applicability and overall efficacy."],"metadata":{"id":"VrsmXosCt1QN"}},{"cell_type":"code","source":["def evaluate_test_data(clf, test_embeddings, test_labels):\n","    \"\"\"\n","    Evaluate the trained classifier on test data.\n","\n","    Parameters:\n","    - clf (object): Trained classifier object.\n","    - test_embeddings (array-like): Feature vectors or embeddings of the test data.\n","    - test_labels (array-like): Labels corresponding to the test data.\n","\n","    Returns:\n","    - test_predictions (array-like): Predicted labels for the test data.\n","    - test_accuracy (float): Accuracy of the classifier on the test data.\n","    \"\"\"\n","\n","    # Perform predictions on test data\n","    test_predictions = clf.predict(test_embeddings)\n","\n","    # Calculate test accuracy\n","    test_accuracy = accuracy_score(test_labels, test_predictions)\n","\n","    return test_predictions, test_accuracy\n"],"metadata":{"id":"NlaZONaDt14E","executionInfo":{"status":"ok","timestamp":1720345660312,"user_tz":-180,"elapsed":300,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Example usage:\n","test_predictions, test_accuracy = evaluate_test_data(clf, test_embeddings, test_labels)\n","#print(\"Test Predictions:\", test_predictions)\n","print(\"Test Accuracy:\", test_accuracy)"],"metadata":{"id":"_X3GAq91t3W1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720345662015,"user_tz":-180,"elapsed":309,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"806f78ec-b886-46d6-ac3b-7ad5136bd856"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.9332591768631813\n"]}]},{"cell_type":"markdown","source":["# ***Presentation of Model Evaluation Metrics***\n","\n","In this critical juncture, we showcase a comprehensive array of evaluation metrics meticulously designed to gauge the efficacy and performance of our model. Through the presentation of these metrics, including but not limited to accuracy, precision, recall, and F1-score, we offer a nuanced understanding of the model's strengths and limitations. This holistic evaluation serves to validate the model's efficacy and aids in informing future iterations or enhancements."],"metadata":{"id":"Pi7aTSl0uHjA"}},{"cell_type":"code","source":["def calculate_confusion_matrix(actual_labels, predicted_labels):\n","    \"\"\"\n","    Calculate the confusion matrix based on actual and predicted labels.\n","\n","    Parameters:\n","    actual_labels (list): List of actual labels (-1 for ads, 1 for podcasts).\n","    predicted_labels (list): List of predicted labels (-1 for ads, 1 for podcasts).\n","\n","    Returns:\n","    tuple: A tuple containing true positives, false positives, true negatives, and false negatives.\n","    \"\"\"\n","    true_positives = 0\n","    false_positives = 0\n","    true_negatives = 0\n","    false_negatives = 0\n","\n","    for actual, predicted in zip(actual_labels, predicted_labels):\n","        if actual == 0 and predicted == 0:  # true_negatives\n","            true_negatives += 1\n","        elif actual == 1 and predicted == 0:  # false_negatives\n","            false_negatives += 1\n","        elif actual == 1 and predicted == 1:  # true_positives\n","            true_positives += 1\n","        elif actual == 0 and predicted == 1:  # false_positives\n","            false_positives += 1\n","\n","    return true_positives, false_positives, true_negatives, false_negatives"],"metadata":{"id":"a4V7gKQGuIeI","executionInfo":{"status":"ok","timestamp":1720345675219,"user_tz":-180,"elapsed":290,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Call the function by passing the actual labels and predicted labels\n","true_positives, false_positives, true_negatives, false_negatives = calculate_confusion_matrix(test_labels, test_predictions)\n","\n","# Print the results\n","print(\"True Positives:\", true_positives)\n","print(\"False Positives:\", false_positives)\n","print(\"True Negatives:\", true_negatives)\n","print(\"False Negatives:\", false_negatives)\n","\n","# Calculate evaluation values\n","precision = true_positives / (true_positives + false_positives)\n","recall = true_positives / (true_positives + false_negatives)\n","specificity = true_negatives / (true_negatives + false_positives)\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","# Print the evaluation values\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"Specificity:\", specificity)\n","print(\"F1 Score:\", f1_score)"],"metadata":{"id":"oSN6mBwguKtK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720345677267,"user_tz":-180,"elapsed":310,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"decc79a2-217f-4e9c-9f9e-f3807f52ae23"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["True Positives: 62\n","False Positives: 19\n","True Negatives: 777\n","False Negatives: 41\n","Precision: 0.7654320987654321\n","Recall: 0.6019417475728155\n","Specificity: 0.9761306532663316\n","F1 Score: 0.6739130434782608\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","# Save the trained model to a file\n","joblib_file = \"random_forest_model_vggish_3sec.pkl\"\n","joblib.dump(clf, joblib_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9-wvsyAGTC9","executionInfo":{"status":"ok","timestamp":1720345707321,"user_tz":-180,"elapsed":303,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"c133d83a-9a71-4c47-b173-5a4dc46fc216"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['random_forest_model_vggish_3sec.pkl']"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["from google.colab import files\n","\n","# Download the file\n","files.download(joblib_file)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"hHfDVaf_GSgH","executionInfo":{"status":"ok","timestamp":1720345709333,"user_tz":-180,"elapsed":298,"user":{"displayName":"Odelia Harroch","userId":"14366637673808063689"}},"outputId":"74337a5f-6266-4c5e-b9d3-b341bbf2fc8b"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c816360b-d312-45ef-9cc5-500888b4057e\", \"random_forest_model_vggish_3sec.pkl\", 383465)"]},"metadata":{}}]}]}